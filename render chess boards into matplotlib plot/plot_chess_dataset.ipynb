{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.patches as patches\n",
    "import hdbscan\n",
    "\n",
    "# for splines\n",
    "from __future__ import division\n",
    "from scipy import interpolate\n",
    "\n",
    "# for coloured density plots\n",
    "import matplotlib.colors\n",
    "from scipy.stats import kde\n",
    "\n",
    "# for density / contours\n",
    "import seaborn as sns\n",
    "\n",
    "# for clustering text\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lichess_umap_seed0_no_duplicate_projection_eco_games.csv\")\n",
    "# df = df.fillna('')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65785e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboard_black = '#EDEEEF'\n",
    "chessboard_white = '#FFFFFF'\n",
    "piece_black = '#000000'\n",
    "piece_white = '#FF0000'#'#FFFFFF'\n",
    "pieces_dict = {\n",
    "#   'wr': '♖',\n",
    "#   'wn': '♘',\n",
    "#   'wb': '♗',\n",
    "#   'wk': '♔',\n",
    "#   'wq': '♕',\n",
    "#   'wp': '♙',\n",
    "  'wr': '♜',\n",
    "  'wn': '♞',\n",
    "  'wb': '♝',\n",
    "  'wk': '♚',\n",
    "  'wq': '♛',\n",
    "  'wp': '♟',\n",
    "  'br': '♜',\n",
    "  'bn': '♞',\n",
    "  'bb': '♝',\n",
    "  'bk': '♚',\n",
    "  'bq': '♛',\n",
    "  'bp': '♟',\n",
    "  '': ''\n",
    "}\n",
    "x_labels = ['a','b','c','d','e','f','g','h']\n",
    "y_labels = [str(y) for y in range(1,9)]\n",
    "features = np.array(np.meshgrid(x_labels,y_labels)).T.reshape(-1,2)\n",
    "features = [''.join(s) for s in features.tolist()]\n",
    "colours = ['#1B9E77', '#D95F02', '#E7298A', '#7570B3', '#66A61E']\n",
    "\n",
    "\n",
    "def get_piece_colour(piece):\n",
    "#     return 'black'\n",
    "    if piece == '':\n",
    "        return 'white'\n",
    "    return piece_black if piece[0] == 'b' else piece_white\n",
    "\n",
    "def get_colour_indices(c):\n",
    "    c_set = sorted(set(c))\n",
    "    c_idx = list(range(len(c_set)))\n",
    "    c_dict = dict(zip(list(c_set), c_idx))\n",
    "    return [c_dict[x] for x in c], c_dict\n",
    "\n",
    "def plot_df(ax, df, c_dict, alpha=1.0, zorder=0, linewidth=1):\n",
    "    x = df['x'].values\n",
    "    y = df['y'].values\n",
    "    c = df['algo'].values\n",
    "    c = colours[c_dict[c[0]]]\n",
    "    ax.plot(x, y, c=c, alpha=alpha, zorder=zorder, linewidth=linewidth)\n",
    "    \n",
    "\n",
    "def plot_df_splines(ax, df, c_dict, alpha=1.0, zorder=0, linewidth=1, spline_smoothing=0):\n",
    "    df = df.drop_duplicates(subset=['x','y'])\n",
    "    x = df['x'].values\n",
    "    y = df['y'].values\n",
    "    c = df['algo'].values\n",
    "    c = colours[c_dict[c[0]]]\n",
    "\n",
    "    tck, u = interpolate.splprep([x,y], s=spline_smoothing, k=min(3, len(x)-1))\n",
    "    xnew,ynew = interpolate.splev(np.linspace(0, 1, len(x)*10), tck, der = 0)\n",
    "    ax.plot(x, y, 'o', xnew, ynew, c=c, alpha=alpha, zorder=zorder, linewidth=linewidth)\n",
    "\n",
    "    \n",
    "def get_board_colour(i,j):\n",
    "    if i%2 == 0:\n",
    "        if j%2 == 0:\n",
    "            return chessboard_black\n",
    "        else:\n",
    "            return chessboard_white\n",
    "    else:\n",
    "        if j%2 == 0:\n",
    "            return chessboard_white\n",
    "        else:\n",
    "            return chessboard_black\n",
    "\n",
    "def get_inverse_board_colour(i, j):\n",
    "    c = get_board_colour(i, j)\n",
    "    if c == chessboard_white:\n",
    "        return chessboard_black\n",
    "    else:\n",
    "        return chessboard_white\n",
    "        \n",
    "            \n",
    "def render_piece(piece, ax, x, y, tile_size, alpha, zorder):\n",
    "    y1, y2 = plt.gca().get_window_extent().get_points()[:, 1]\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    yscale = (y2-y1)/(ymax-ymin)\n",
    "    fontsize = tile_size*yscale\n",
    "    ax.text(x, y, pieces_dict[piece], size=fontsize, color=get_piece_colour(piece), alpha=alpha, zorder=zorder)\n",
    "            \n",
    "            \n",
    "def render_chessboard(ax, x, y, size, zorder, chessboard_dict):\n",
    "    tile_s = size/8\n",
    "    x_o = x-size/2\n",
    "    y_o = y-size/2\n",
    "    rect = patches.Rectangle((x_o-size/32, y_o-size/32), size*34/32, size*34/32, linewidth=1, edgecolor='black', facecolor='black', zorder=zorder)\n",
    "    ax.add_patch(rect)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            x_now = x_o + i * tile_s\n",
    "            y_now = y_o + j * tile_s\n",
    "            c = get_board_colour(i, j)\n",
    "            rect = patches.Rectangle((x_now, y_now), tile_s, tile_s, linewidth=1, edgecolor=c, facecolor=c, zorder=zorder)\n",
    "            ax.add_patch(rect)\n",
    "            piece, alpha = chessboard_dict[x_labels[i]+y_labels[j]]\n",
    "            render_piece(piece, ax, x_now, y_now, tile_s, alpha, zorder)\n",
    "\n",
    "            \n",
    "def cluster_chessboard_dict(cluster_i):\n",
    "    chessboard_dict = {}\n",
    "    for f in features:\n",
    "        piece, frequency = get_piece_frequency_from_cluster_field(cluster_i, f)\n",
    "        chessboard_dict[f] = (piece, frequency)\n",
    "    return chessboard_dict\n",
    "            \n",
    "            \n",
    "def get_cluster_positions(df, clusterer, drop_noise=True):\n",
    "    # create cluster_array where each sample represents one cluster and the 1st and 2nd column represent x and y coordinate of that cluster\n",
    "    x = df['x'].values\n",
    "    y = df['y'].values\n",
    "    \n",
    "    # add labels and probabilities to each sample, calculate cluster x/y/count\n",
    "    samples = np.zeros(shape=(len(x), 4))\n",
    "    samples[:,0] = x\n",
    "    samples[:,1] = y\n",
    "    clusters = np.zeros(shape=(len(set(clusterer.labels_)), 2))\n",
    "    counts = np.zeros(shape=(len(set(clusterer.labels_))))\n",
    "    for i in range(len(clusterer.labels_)):\n",
    "        c_id = clusterer.labels_[i]\n",
    "        c_prob = clusterer.probabilities_[i]\n",
    "        samples[i,2] = c_id\n",
    "        samples[i,3] = c_prob\n",
    "        \n",
    "        clusters[c_id,0] += samples[i,0]# * c_prob\n",
    "        clusters[c_id,1] += samples[i,1]# * c_prob\n",
    "        counts[c_id] += 1\n",
    "        \n",
    "    clusters = (clusters.T / counts).T\n",
    "    return clusters[:-1], counts[:-1]\n",
    "\n",
    "\n",
    "# method for accessing cluster i, field f and return most frequent piece, and its relative frequency\n",
    "def get_piece_frequency_from_cluster_field(cluster_i, field, ignore_empty_fields=True):\n",
    "    counts = df.loc[df['cluster']==cluster_i][field].fillna('').value_counts(normalize=True)\n",
    "    if ignore_empty_fields and '' in counts and len(counts) != 1:\n",
    "        counts = counts.drop('')\n",
    "    return counts.idxmax(), counts[counts.idxmax()]\n",
    "\n",
    "\n",
    "# map the relative frequency of the cluster into a given scale depending on min and max frequencies\n",
    "def get_cluster_scale(cluster_i, min_scale, max_scale, drop_noise=True):\n",
    "#     i_scale = df[['cluster']].value_counts(normalize=True)[cluster_i]\n",
    "    if drop_noise: \n",
    "        counts = cluster_value_counts_without_noise\n",
    "    else:\n",
    "        counts = cluster_value_counts\n",
    "    min1, max1, min2, max2, v1 = counts.min(), counts.max(), min_scale, max_scale, counts[cluster_i]\n",
    "    return (v1-min1)/(max1-min1) * (max2-min2) + min2\n",
    "\n",
    "\n",
    "# https://www.python-graph-gallery.com/85-density-plot-with-matplotlib\n",
    "def render_density(ax, df):\n",
    "    # create data\n",
    "    x = df['x'].values\n",
    "    y = df['y'].values\n",
    "\n",
    "    # Evaluate a gaussian kde on a regular grid of nbins x nbins over data extents\n",
    "    nbins=100\n",
    "    k = kde.gaussian_kde([x,y])\n",
    "    xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "    \n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"grey\"])\n",
    "    ax.pcolormesh(xi, yi, zi.reshape(xi.shape), shading='auto', cmap=cmap, alpha=1.0, zorder=-1)\n",
    "    \n",
    "    \n",
    "# https://seaborn.pydata.org/generated/seaborn.kdeplot.html\n",
    "def render_contours(ax, df, fill=False, alpha=0.5):\n",
    "    sns.kdeplot(data=df, x='x', y='y', hue='cluster', fill=fill, ax=ax, alpha=alpha, zorder=-2)\n",
    "    \n",
    "    \n",
    "def get_text_clusters(words: np.ndarray):    \n",
    "    # words = \"open opening openings stem stemming stemmed\".split(\" \") #Replace this line\n",
    "    # words = np.asarray(words) #So that indexing with a list will work\n",
    "    lev_similarity = -1*np.array([[distance.levenshtein(w1,w2) for w1 in words] for w2 in words])\n",
    "\n",
    "    affprop = AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "    affprop.fit(lev_similarity)\n",
    "    cluster_dict = {}\n",
    "    for cluster_id in np.unique(affprop.labels_):\n",
    "        exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "        cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "        cluster_str = \", \".join(cluster)\n",
    "#         print(\" - *%s:* %s\" % (exemplar, cluster_str))\n",
    "        cluster_dict[exemplar] = cluster\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be01faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['x'].values\n",
    "y = df['y'].values\n",
    "c = df['algo'].values\n",
    "\n",
    "cs, c_dict = get_colour_indices(c)\n",
    "c = [colours[i] for i in cs]\n",
    "print(c_dict)\n",
    "print(colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x,y]).T\n",
    "\n",
    "# TODO clustering based on ECO codes or opening names (get sorted list of most common substrings and then k biggest clusters)\n",
    "\n",
    "min_cluster_size = 50\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "clusterer.fit(X)\n",
    "clusters, counts = get_cluster_positions(df, clusterer, drop_noise=True)\n",
    "df['cluster'] = clusterer.labels_\n",
    "cluster_value_counts = df[['cluster']].value_counts(normalize=True)\n",
    "cluster_value_counts_without_noise = df[df['cluster']!=-1][['cluster']].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zorder = 0\n",
    "size = 200\n",
    "fig, axes = plt.subplots(1,1)\n",
    "ax = axes\n",
    "fig.set_figheight(size)\n",
    "fig.set_figwidth(size)\n",
    "ax.axis('equal')\n",
    "ax.scatter(x,y,c=c,zorder=zorder,s=size*10,alpha=0.5)\n",
    "# ax.scatter(clusters[:,0], clusters[:,1], s=size*50, zorder=zorder)\n",
    "dfs = dict(tuple(df.groupby('line')))\n",
    "for key in dfs:\n",
    "    # TODO consider catmull rom splines - code : https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline\n",
    "    plot_df_splines(ax, dfs[key], c_dict, alpha=0.1, zorder=zorder, linewidth=size/20, spline_smoothing=0.01)\n",
    "ax.axis( [ x.min() - 1 , x.max() + 1 , y.min() - 1 , y.max() + 1 ] )\n",
    "\n",
    "# TODO also consider physics to stop them from overlapping, and maybe a line that attaches them to their original position\n",
    "for (i, cluster_i) in enumerate(zip(range(len(clusters)))):\n",
    "#     render_density(ax, df[df['cluster']==cluster_i])\n",
    "#     render_contours(ax, df[df['cluster']==cluster_i], fill=True)\n",
    "    scale = get_cluster_scale(cluster_i, 1.0/4, 1.0)\n",
    "    render_chessboard(ax, clusters[cluster_i,0], clusters[cluster_i,1], scale, zorder+scale+1, cluster_chessboard_dict(cluster_i))\n",
    "\n",
    "fig.savefig('cluster_size_'+str(min_cluster_size)+'.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO once clusters are connected consider animated change of summary visualization versus difference visualization as labels, given that we do not have actions between samples in the data\n",
    "# TODO consdier difference visualization where 2 chessboards are overlayed and slightly juxtaposed\n",
    "# such that within each field we see previous and following piece, encoded by different colours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d7d79ed15a01c4499ca4e27a5c405c591f28c95808e2b7444d4034c940355b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
